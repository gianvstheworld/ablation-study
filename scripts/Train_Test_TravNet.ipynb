{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Importando bibliotecas úteis para a rede\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.ops import box_iou\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as torch_utils\n",
    "import torch.nn as nn\n",
    "\n",
    "# Importando TravNet e seu dataset\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "from models.TravNet_Filters import TravNet_Filters # EDITAR AQUI CASO QUEIRA TESTAR COM/SEM PROFUNDIDADE\n",
    "from utils.TravDataloader import TravNetDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "params = Object() # Cria um objeto para armazenar os parâmetros\n",
    "# Parametros do dataset\n",
    "params.data_path        = r'../../data/' \n",
    "params.csv_path         = os.path.join(params.data_path, 'data.csv')\n",
    "params.preproc          = True  # Vertical flip augmentation - inverte a imagem verticalmente\n",
    "params.depth_mean       = 3.5235\n",
    "params.depth_std        = 10.6645\n",
    "\n",
    "# Parametros de treino\n",
    "params.seed             = 230 # Seed para o gerador de números aleatórios - como saber a melhor seed para o modelo?\n",
    "params.epochs           = 10 # MUDAR AQUI AS ÉPOCAS\n",
    "params.batch_size       = 16\n",
    "params.learning_rate    = 1e-4\n",
    "params.weight_decay     = 1e-5\n",
    "\n",
    "# Parametros do modelo \n",
    "params.pretrained = True\n",
    "params.load_network_path = None \n",
    "params.input_size       = (424, 240)\n",
    "params.output_size      = (424, 240)\n",
    "params.output_channels  = 1\n",
    "params.bottleneck_dim   = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(params.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(params.seed) \n",
    "\n",
    "# Selecionar GPU ou CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Transformações para o dataset\n",
    "    # Pré-estudo ablativo - Alterar aqui\n",
    "    transform = transforms.Compose([\n",
    "                transforms.ToPILImage(), # Converte o tensor para uma imagem PIL\n",
    "                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "                transforms.RandomChoice([\n",
    "                    transforms.RandomHorizontalFlip(p=1),\n",
    "                    transforms.RandomRotation(15),\n",
    "                    transforms.RandomInvert(0.5),\n",
    "                ]),\n",
    "                transforms.ToTensor(), # Converte a imagem PIL para um tensor\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normaliza o tensor (média e desvio padrão)\n",
    "                ])\n",
    "    \n",
    "    '''\n",
    "    transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "    '''\n",
    "\n",
    "    dataset = TravNetDataset(params, transform)\n",
    "\n",
    "    # Divide o dataset em treino e validação \n",
    "    train_size, val_size = int(0.8*len(dataset)), np.ceil(0.2*len(dataset)).astype('int')\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size]) # Separa os dados de acordo com os tamanhos estabelecidos e embaralha\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params.batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=params.batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    print('Total loaded %d images' % len(dataset))\n",
    "    print('Loaded %d train images' % train_size)\n",
    "    print('Loaded %d valid images' % val_size)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(ground_truth_bbox, prediction_bbox):\n",
    "    \n",
    "    # Plotando imagens \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "    ax[0].imshow(ground_truth_bbox)\n",
    "    ax[0].set_title('Ground Truth')\n",
    "    ax[1].imshow(prediction_bbox)\n",
    "    ax[1].set_title('Prediction')\n",
    "    plt.show()    \n",
    "\n",
    "    iou = box_iou(ground_truth_bbox, prediction_bbox)\n",
    "    print('IOU : ', iou.numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pré-estudo ablativo - Alterar aqui\n",
    "def fit(net, criterion, optimizer, scheduler, train_loader, val_loader):    \n",
    "\n",
    "    # Pré-estudo ablativo - Alterar aqui\n",
    "    patience = 10 # Número de épocas sem melhora na perda de validação para parar o treinamento\n",
    "    counter = 0 \n",
    "\n",
    "    best_val_loss = np.inf \n",
    "    train_loss_list = [] \n",
    "    val_loss_list = [] \n",
    "\n",
    "    for epoch in range(params.epochs):\n",
    "        net.train()\n",
    "        train_loss = 0.0 \n",
    "        \n",
    "        for i, data in enumerate(train_loader):\n",
    "            data = (item.to(device).type(torch.float32) for item in data) \n",
    "            color_img, depth_img, path_img, mu_img, nu_img, weight = data \n",
    "\n",
    "            # Forward pass\n",
    "            pred = net(color_img, depth_img) # EDITAR AQUI CASO QUEIRA TESTAR COM/SEM PROFUNDIDADE\n",
    "            label = mu_img\n",
    "\n",
    "            loss = weight*criterion(pred*path_img, label) \n",
    "            loss = torch.mean(loss)\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "\n",
    "            train_loss += loss.item() \n",
    "\n",
    "        train_loss /= len(train_loader) \n",
    "        train_loss_list.append(train_loss) \n",
    "\n",
    "        if (epoch) % 10 == 0:\n",
    "            outstring = 'Epoch [%d/%d], Loss: ' % (epoch+1, params.epochs)\n",
    "            print(outstring, train_loss)\n",
    "            print('Learning Rate for this epoch: {}'.format(optimizer.param_groups[0]['lr']))\n",
    "\n",
    "        # Testando o modelo \n",
    "        with torch.no_grad():\n",
    "            net.eval() \n",
    "\n",
    "            val_loss = 0.0 \n",
    "\n",
    "            for i, data in enumerate(val_loader):\n",
    "                data = (item.to(device).type(torch.float32) for item in data)\n",
    "                color_img, depth_img, path_img, mu_img, nu_img, weight = data\n",
    "\n",
    "                pred = net(color_img, depth_img) # EDITAR AQUI CASO QUEIRA TESTAR COM/SEM PROFUNDIDADE\n",
    "                label = mu_img\n",
    "\n",
    "                loss = weight*criterion(pred*path_img, label)\n",
    "                loss = torch.mean(loss)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            val_loss_list.append(val_loss)\n",
    "        \n",
    "            # Pré-estudo ablativo - Alterar aqui   \n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                counter = 0\n",
    "\n",
    "                # Salva o modelo\n",
    "                print('Updating best validation loss: %.5f' % best_val_loss)\n",
    "                torch.save(net.state_dict(), 'checkpoints/best_predictor_depth.pth')\n",
    "\n",
    "            else:\n",
    "                counter += 1\n",
    "                print('No improvement since last epoch: %d' % counter)\n",
    "                if counter >= patience:\n",
    "                    net.module.load_state_dict(torch.load('checkpoints/best_predictor_depth.pth'))\n",
    "                    print('Early stopping!')\n",
    "                    break\n",
    "\n",
    "        # Pré-estudo ablativo - Alterar aqui    \n",
    "        scheduler.step() \n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            plt.figure(figsize = (14,14))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(color_img[0].permute(1, 2, 0).cpu().numpy())\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(255*pred[0,0,:,:].detach().cpu().numpy(), vmin=0, vmax=255)\n",
    "            plt.show(block=False)\n",
    "\n",
    "            get_iou(label[0], pred[0,0,:,:].detach().cpu().numpy())\n",
    "\n",
    "    print('Training Loss list: ', train_loss_list)\n",
    "    print('Validation Loss list: ', val_loss_list)\n",
    "\n",
    "    plt.plot(train_loss_list, label='Treinamento')\n",
    "    plt.plot(val_loss_list, label='Validação')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Perda')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "# REINICIALIZAR AQUI\n",
    "net = TravNet_Filters(params) # Instancia a rede - # EDITAR AQUI CASO QUEIRA TESTAR COM/SEM PROFUNDIDADE\n",
    "\n",
    "# Usado para carregar um modelo salvo\n",
    "if params.load_network_path is not None:\n",
    "    print('Loading saved network from {}'.format(params.load_network_path))\n",
    "    net.load_state_dict(torch.load(params.load_network_path))\n",
    "\n",
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\") \n",
    "net = torch.nn.DataParallel(net).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 15, 27])\n",
      "test.shape: torch.Size([2, 1, 240, 424])\n"
     ]
    }
   ],
   "source": [
    "# Inicializa um tensor de teste\n",
    "# EDITAR AQUI CASO QUEIRA TESTAR COM/SEM PROFUNDIDADE\n",
    "test = net(torch.rand([2, 3, params.input_size[1], params.input_size[0]]).to(device), torch.rand([2, 1, params.input_size[1], params.input_size[0]]).to(device))\n",
    "print('test.shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gian/Documentos/Códigos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb Célula 10\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_data, val_data \u001b[39m=\u001b[39m load_data()\n",
      "\u001b[1;32m/home/gian/Documentos/Códigos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb Célula 10\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m             transforms\u001b[39m.\u001b[39mToPILImage(), \u001b[39m# Converte o tensor para uma imagem PIL\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             transforms\u001b[39m.\u001b[39mColorJitter(brightness\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, contrast\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, saturation\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, hue\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m             transforms\u001b[39m.\u001b[39mNormalize(mean\u001b[39m=\u001b[39m[\u001b[39m0.485\u001b[39m, \u001b[39m0.456\u001b[39m, \u001b[39m0.406\u001b[39m], std\u001b[39m=\u001b[39m[\u001b[39m0.229\u001b[39m, \u001b[39m0.224\u001b[39m, \u001b[39m0.225\u001b[39m]), \u001b[39m# Normaliza o tensor (média e desvio padrão)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m             ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mtransform = transforms.Compose([\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m        transforms.ToPILImage(),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m        ])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m dataset \u001b[39m=\u001b[39m TravNetDataset(params, transform)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Divide o dataset em treino e validação \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m train_size, val_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39m0.8\u001b[39m\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(dataset)), np\u001b[39m.\u001b[39mceil(\u001b[39m0.2\u001b[39m\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(dataset))\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documentos/Códigos/IC/ablation-study/scripts/../src/utils/TravDataloader.py:40\u001b[0m, in \u001b[0;36mTravNetDataset.__init__\u001b[0;34m(self, params, transform)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolor_fname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdepth_fname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath_fname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmu_fname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnu_fname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n\u001b[1;32m     39\u001b[0m \u001b[39m# Prepara os pesos e o número de intervalos definidos \u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbins \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_weights()\n\u001b[1;32m     42\u001b[0m \u001b[39m# Obtém as estatísticas de profundidade\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_depth_stats()\n",
      "File \u001b[0;32m~/Documentos/Códigos/IC/ablation-study/scripts/../src/utils/TravDataloader.py:172\u001b[0m, in \u001b[0;36mTravNetDataset.prepare_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m path_fname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath_fname[idx]\n\u001b[1;32m    171\u001b[0m \u001b[39m# Carrega as imagens\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m mu_img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot, mu_fname), \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    173\u001b[0m mu_img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(mu_img, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_size, interpolation\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mINTER_AREA)\n\u001b[1;32m    174\u001b[0m mu_img \u001b[39m=\u001b[39m mu_img\u001b[39m/\u001b[39m\u001b[39m255.0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data, val_data = load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = iter(train_data)\n",
    "data = next(data_iterator)\n",
    "first_image = data[0][0]\n",
    "first_image = torch_utils.make_grid(first_image)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(first_image.permute(1, 2, 0))\n",
    "plt.title('First image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training tools and fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.L1Loss(reduction='none') # Perda L1 (erro absoluto médio)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=params.learning_rate, weight_decay=params.weight_decay) # Verificar o melhor otimizador para o modelo\n",
    "# Pré-estudo ablativo - Alterar aqui   \n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,20], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train = fit(net=net, criterion=criterion, optimizer=optimizer, train_loader=train_data, val_loader=val_data)\n",
    "# Pré-estudo ablativo - Alterar aqui \n",
    "train = fit(net=net, criterion=criterion, optimizer=optimizer, scheduler=scheduler, train_loader=train_data, val_loader=val_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
