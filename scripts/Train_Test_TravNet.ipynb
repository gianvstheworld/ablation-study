{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Importando bibliotecas úteis para a rede\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as torch_utils\n",
    "import torch.nn as nn\n",
    "\n",
    "# Importando TravNet e seu dataset\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "from models.TravNet_WOBlocks import TravNet\n",
    "# from models.TravNet_ViT import VisualTransformer # ADICIONAR ViT\n",
    "# from models.TravNet_ViT import CustomTransformer # ADICIONAR ViT\n",
    "from utils.TravDataloader import TravNetDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "params = Object() # Cria um objeto para armazenar os parâmetros\n",
    "# Parametros do dataset\n",
    "params.data_path        = r'../../data/' \n",
    "params.csv_path         = os.path.join(params.data_path, 'data.csv')\n",
    "params.preproc          = True  # Vertical flip augmentation - inverte a imagem verticalmente\n",
    "params.depth_mean       = 3.5235\n",
    "params.depth_std        = 10.6645\n",
    "\n",
    "# Parametros de treino\n",
    "params.seed             = 230 # Seed para o gerador de números aleatórios - como saber a melhor seed para o modelo?\n",
    "params.epochs           = 25 # MUDAR AQUI AS ÉPOCAS\n",
    "params.batch_size       = 16\n",
    "params.learning_rate    = 1e-4\n",
    "params.weight_decay     = 1e-5\n",
    "\n",
    "# Parametros do modelo \n",
    "params.pretrained = True\n",
    "params.load_network_path = None \n",
    "params.input_size       = (424, 240)\n",
    "params.output_size      = (424, 240)\n",
    "params.output_channels  = 1\n",
    "params.bottleneck_dim   = 256\n",
    "\n",
    "# Parametros da ViT\n",
    "transformer_params = Object()\n",
    "transformer_params.in_channels = 3\n",
    "transformer_params.hidden_dim = 256\n",
    "transformer_params.num_heads = 8\n",
    "transformer_params.num_layers = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(params.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(params.seed) \n",
    "\n",
    "# Selecionar GPU ou CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Transformações para o dataset\n",
    "    # Pré-estudo ablativo - Alterar aqui\n",
    "    transform = transforms.Compose([\n",
    "                transforms.ToPILImage(), # Converte o tensor para uma imagem PIL\n",
    "                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "                transforms.RandomChoice([\n",
    "                    transforms.RandomHorizontalFlip(p=1),\n",
    "                    transforms.RandomRotation(15),\n",
    "                    transforms.RandomInvert(0.5),\n",
    "                ]),\n",
    "                transforms.ToTensor(), # Converte a imagem PIL para um tensor\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normaliza o tensor (média e desvio padrão)\n",
    "                ])\n",
    "    \n",
    "    '''\n",
    "    transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "    '''\n",
    "\n",
    "    dataset = TravNetDataset(params, transform)\n",
    "\n",
    "    # Divide o dataset em treino e validação \n",
    "    train_size, val_size = int(0.8*len(dataset)), np.ceil(0.2*len(dataset)).astype('int')\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size]) # Separa os dados de acordo com os tamanhos estabelecidos e embaralha\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params.batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=params.batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    print('Total loaded %d images' % len(dataset))\n",
    "    print('Loaded %d train images' % train_size)\n",
    "    print('Loaded %d valid images' % val_size)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box(binary_image):\n",
    "    binary_image_np = binary_image.detach().cpu().numpy()\n",
    "    binary_image_np = np.where(binary_image_np > 0.5, 255, 0).astype(np.uint8)\n",
    "\n",
    "    contours, _ = cv2.findContours(binary_image_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    bounding_boxes = []\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, largura, altura = cv2.boundingRect(contour)\n",
    "        bounding_boxes.append((x, y, largura, altura))\n",
    "\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(ground_truth, predicted):\n",
    "    iou_list = []\n",
    "\n",
    "    for gt_box, pred_box in zip(ground_truth, predicted):\n",
    "        x1_1, y1_1, largura_1, altura_1 = gt_box\n",
    "        x1_2, y1_2, largura_2, altura_2 = pred_box\n",
    "\n",
    "        x2_1 = x1_1 + largura_1\n",
    "        y2_1 = y1_1 + altura_1\n",
    "        x2_2 = x1_2 + largura_2\n",
    "        y2_2 = y1_2 + altura_2\n",
    "\n",
    "        x_overlap = max(0, min(x2_1, x2_2) - max(x1_1, x1_2))\n",
    "        y_overlap = max(0, min(y2_1, y2_2) - max(y1_1, y1_2))\n",
    "        intersection = x_overlap * y_overlap\n",
    "\n",
    "        gt_area = largura_1 * altura_1\n",
    "        pred_area = largura_2 * altura_2\n",
    "\n",
    "        if gt_area == 0 or pred_area == 0:\n",
    "            iou = 0.0  # Evitar divisão por zero\n",
    "        else:\n",
    "            iou = intersection / (gt_area + pred_area - intersection)\n",
    "        \n",
    "        iou_list.append(iou)\n",
    "\n",
    "    return iou_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(path_img, pred_img):\n",
    "    bounding_box_path = get_bounding_box(path_img[0, 0, :, :])\n",
    "    bounding_box_pred = get_bounding_box(pred_img[0, 0, :, :])\n",
    "\n",
    "    iou_val = get_iou(bounding_box_path, bounding_box_pred)\n",
    "\n",
    "    path_img_np = path_img[0, 0, :, :].cpu().numpy()\n",
    "    pred_img_np = pred_img[0, 0, :, :].cpu().numpy()\n",
    "\n",
    "    combined_image = np.zeros_like(path_img_np)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(path_img_np, cmap='gray')  \n",
    "    plt.title(\"path_img com Bounding Boxes\")\n",
    "    for box in bounding_box_path:\n",
    "        x, y, w, h = box\n",
    "        plt.gca().add_patch(plt.Rectangle((x, y), w, h, fill=False, edgecolor='red'))\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(pred_img_np, cmap='gray')  \n",
    "    plt.title(\"pred_img com Bounding Boxes\")\n",
    "    for box in bounding_box_pred:\n",
    "        x, y, w, h = box\n",
    "        plt.gca().add_patch(plt.Rectangle((x, y), w, h, fill=False, edgecolor='blue'))\n",
    "    plt.show()\n",
    "\n",
    "    for box in bounding_box_pred:\n",
    "        x, y, w, h = box\n",
    "        combined_image[y:y+h, x:x+w] = 0.5 * pred_img_np[y:y+h, x:x+w] + 0.5 * combined_image[y:y+h, x:x+w]\n",
    "\n",
    "    for box in bounding_box_path:\n",
    "        x, y, w, h = box\n",
    "        combined_image[y:y+h, x:x+w] = 0.5 * path_img_np[y:y+h, x:x+w] + 0.5 * combined_image[y:y+h, x:x+w]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(combined_image, cmap='gray')\n",
    "    \n",
    "    if iou_val:  \n",
    "        plt.title(f\"IoU = {iou_val[0]:.2f}\") \n",
    "    else:\n",
    "        plt.title(\"IoU não disponível\")    \n",
    "    \n",
    "    for box in bounding_box_path:\n",
    "        x, y, w, h = box\n",
    "        plt.gca().add_patch(plt.Rectangle((x, y), w, h, fill=False, edgecolor='red'))\n",
    "    \n",
    "    for box in bounding_box_pred:\n",
    "        x, y, w, h = box\n",
    "        plt.gca().add_patch(plt.Rectangle((x, y), w, h, fill=False, edgecolor='blue'))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-estudo ablativo - Alterar aqui\n",
    "def fit(net, criterion, optimizer, scheduler, train_loader, val_loader):    \n",
    "\n",
    "    # Pré-estudo ablativo - Alterar aqui\n",
    "    patience = 10 # Número de épocas sem melhora na perda de validação para parar o treinamento\n",
    "    counter = 0 \n",
    "\n",
    "    best_val_loss = np.inf \n",
    "    train_loss_list = [] \n",
    "    val_loss_list = [] \n",
    "\n",
    "    for epoch in range(params.epochs):\n",
    "        net.train()\n",
    "        train_loss = 0.0 \n",
    "        \n",
    "        for i, data in enumerate(train_loader):\n",
    "            data = (item.to(device).type(torch.float32) for item in data) \n",
    "            color_img, depth_img, path_img, mu_img, nu_img, weight = data \n",
    "\n",
    "            # Forward pass\n",
    "            pred = net(color_img, depth_img) # EDITAR AQUI CASO QUEIRA TESTAR COM/SEM PROFUNDIDADE\n",
    "            label = mu_img\n",
    "\n",
    "            loss = weight*criterion(pred*path_img, label) \n",
    "            loss = torch.mean(loss)\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "\n",
    "            train_loss += loss.item() \n",
    "\n",
    "        train_loss /= len(train_loader) \n",
    "        train_loss_list.append(train_loss) \n",
    "\n",
    "        if (epoch) % 10 == 0:\n",
    "            outstring = 'Epoch [%d/%d], Loss: ' % (epoch+1, params.epochs)\n",
    "            print(outstring, train_loss)\n",
    "            print('Learning Rate for this epoch: {}'.format(optimizer.param_groups[0]['lr']))\n",
    "\n",
    "        # Testando o modelo \n",
    "        with torch.no_grad():\n",
    "            net.eval() \n",
    "\n",
    "            val_loss = 0.0 \n",
    "\n",
    "            for i, data in enumerate(val_loader):\n",
    "                data = (item.to(device).type(torch.float32) for item in data)\n",
    "                color_img, depth_img, path_img, mu_img, nu_img, weight = data\n",
    "\n",
    "                pred = net(color_img, depth_img) # EDITAR AQUI CASO QUEIRA TESTAR COM/SEM PROFUNDIDADE\n",
    "                label = mu_img\n",
    "\n",
    "                loss = weight*criterion(pred*path_img, label)\n",
    "                loss = torch.mean(loss)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            val_loss_list.append(val_loss)\n",
    "        \n",
    "            # Pré-estudo ablativo - Alterar aqui   \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                counter = 0\n",
    "\n",
    "                # Salva o modelo\n",
    "                print('Updating best validation loss: %.5f' % best_val_loss)\n",
    "                torch.save(net.state_dict(), 'checkpoints/best_predictor_depth.pth')\n",
    "\n",
    "            else:\n",
    "                counter += 1\n",
    "                print('No improvement since last epoch: %d' % counter)\n",
    "                if counter >= patience:\n",
    "                    net.module.load_state_dict(torch.load('checkpoints/best_predictor_depth.pth'))\n",
    "                    print('Early stopping!')\n",
    "                    break\n",
    "\n",
    "        # Pré-estudo ablativo - Alterar aqui    \n",
    "        scheduler.step() \n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            plt.figure(figsize = (14,14))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(color_img[0].permute(1, 2, 0).cpu().numpy())\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(255*pred[0,0,:,:].detach().cpu().numpy(), vmin=0, vmax=255)\n",
    "            plt.show(block=False)\n",
    "            \n",
    "            draw_bounding_boxes(path_img, pred)\n",
    "\n",
    "    print('Training Loss list: ', train_loss_list)\n",
    "    print('Validation Loss list: ', val_loss_list)\n",
    "\n",
    "    plt.plot(train_loss_list, label='Treinamento')\n",
    "    plt.plot(val_loss_list, label='Validação')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Perda')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "# REINICIALIZAR AQUI\n",
    "net = TravNet(params) # Instancia a rede - # EDITAR AQUI CASO QUEIRA TESTAR COM/SEM PROFUNDIDADE\n",
    "\n",
    "# Usado para carregar um modelo salvo\n",
    "if params.load_network_path is not None:\n",
    "    print('Loading saved network from {}'.format(params.load_network_path))\n",
    "    net.load_state_dict(torch.load(params.load_network_path))\n",
    "\n",
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\") \n",
    "net = torch.nn.DataParallel(net).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.shape: torch.Size([2, 1, 240, 424])\n"
     ]
    }
   ],
   "source": [
    "# Inicializa um tensor de teste\n",
    "# EDITAR AQUI CASO QUEIRA TESTAR COM/SEM PROFUNDIDADE\n",
    "test = net(torch.rand([2, 3, params.input_size[1], params.input_size[0]]).to(device), torch.rand([2, 1, params.input_size[1], params.input_size[0]]).to(device))\n",
    "print('test.shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/gian/Documentos/Códigos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb Célula 12\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_data, val_data \u001b[39m=\u001b[39m load_data()\n",
      "\u001b[1;32m/home/gian/Documentos/Códigos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb Célula 12\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m             transforms\u001b[39m.\u001b[39mToPILImage(), \u001b[39m# Converte o tensor para uma imagem PIL\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             transforms\u001b[39m.\u001b[39mColorJitter(brightness\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, contrast\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, saturation\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, hue\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m             transforms\u001b[39m.\u001b[39mNormalize(mean\u001b[39m=\u001b[39m[\u001b[39m0.485\u001b[39m, \u001b[39m0.456\u001b[39m, \u001b[39m0.406\u001b[39m], std\u001b[39m=\u001b[39m[\u001b[39m0.229\u001b[39m, \u001b[39m0.224\u001b[39m, \u001b[39m0.225\u001b[39m]), \u001b[39m# Normaliza o tensor (média e desvio padrão)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m             ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mtransform = transforms.Compose([\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m        transforms.ToPILImage(),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m        ])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m dataset \u001b[39m=\u001b[39m TravNetDataset(params, transform)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X14sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Divide o dataset em treino e validação \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gian/Documentos/C%C3%B3digos/IC/ablation-study/scripts/Train_Test_TravNet.ipynb#X14sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m train_size, val_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39m0.8\u001b[39m\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(dataset)), np\u001b[39m.\u001b[39mceil(\u001b[39m0.2\u001b[39m\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(dataset))\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documentos/Códigos/IC/ablation-study/scripts/../src/utils/TravDataloader.py:34\u001b[0m, in \u001b[0;36mTravNetDataset.__init__\u001b[0;34m(self, params, transform)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbin_width \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m  \u001b[39m# Largura da máscara binária\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m# Lê as linhas do arquivo csv\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(params\u001b[39m.\u001b[39;49mcsv_path)\n\u001b[1;32m     36\u001b[0m \u001b[39m# Prepara os dados e obtém os valores máximos e mínimos\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolor_fname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdepth_fname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath_fname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmu_fname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnu_fname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    571\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    572\u001b[0m     dialect,\n\u001b[1;32m    573\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    583\u001b[0m )\n\u001b[1;32m    584\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 586\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:488\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    487\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 488\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1047\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, nrows\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1046\u001b[0m     nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m-> 1047\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[1;32m   1049\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1050\u001b[0m         \u001b[39mif\u001b[39;00m col_dict:\n\u001b[1;32m   1051\u001b[0m             \u001b[39m# Any column is actually fine:\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:223\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 223\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    224\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    225\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:801\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:857\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1925\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "train_data, val_data = load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = iter(train_data)\n",
    "data = next(data_iterator)\n",
    "first_image = data[0][0]\n",
    "first_image = torch_utils.make_grid(first_image)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(first_image.permute(1, 2, 0))\n",
    "plt.title('First image')\n",
    "plt.show() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training tools and fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.L1Loss(reduction='none') # Perda L1 (erro absoluto médio)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=params.learning_rate, weight_decay=params.weight_decay) # Verificar o melhor otimizador para o modelo\n",
    "# Pré-estudo ablativo - Alterar aqui   \n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,20], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train = fit(net=net, criterion=criterion, optimizer=optimizer, train_loader=train_data, val_loader=val_data)\n",
    "# Pré-estudo ablativo - Alterar aqui \n",
    "train = fit(net=net, criterion=criterion, optimizer=optimizer, scheduler=scheduler, train_loader=train_data, val_loader=val_data) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
