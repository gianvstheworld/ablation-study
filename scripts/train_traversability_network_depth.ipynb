{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Importando bibliotecas úteis para a rede\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Importando TravNet e seu dataset\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "from models.resnet_depth_unet import ResnetDepthUnet\n",
    "from utils.dataloader import TraversabilityDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Object(object):\n",
    "    '''\n",
    "    Classe para criar objetos - ponto de partida para hierarquia de classes \n",
    "    '''\n",
    "    pass\n",
    "\n",
    "params = Object() # Cria um objeto para armazenar os parâmetros\n",
    "# Parametros do dataset\n",
    "params.data_path        = r'/home/gian/Documentos/Códigos/IC/ablation-study/data/' \n",
    "params.csv_path         = os.path.join(params.data_path, 'data.csv')\n",
    "params.preproc          = True  # Vertical flip augmentation - inverte a imagem verticalmente\n",
    "params.depth_mean       = 3.5235\n",
    "params.depth_std        = 10.6645\n",
    "\n",
    "# Parametros de treino\n",
    "params.seed             = 230 # Seed para o gerador de números aleatórios - como saber a melhor seed para o modelo?\n",
    "params.epochs           = 50\n",
    "params.batch_size       = 16\n",
    "params.learning_rate    = 1e-4\n",
    "params.weight_decay     = 1e-5\n",
    "\n",
    "# Parametros do modelo \n",
    "params.pretrained = True\n",
    "params.load_network_path = None \n",
    "params.input_size       = (424, 240)\n",
    "params.output_size      = (424, 240)\n",
    "params.output_channels  = 1\n",
    "params.bottleneck_dim   = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(params.seed) # Passa a seed para a CPU\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(params.seed) # Caso disponível, passa a seed para a GPU\n",
    "\n",
    "# Selecionar GPU ou CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "net = ResnetDepthUnet(params) # Instancia um objeto da classe ResnetDepthUnet\n",
    "# summary(net,(3, 424, 240)) # Mostra um resumo da rede\n",
    "\n",
    "# Usado para carregar um modelo salvo\n",
    "if params.load_network_path is not None:\n",
    "    print('Loading saved network from {}'.format(params.load_network_path))\n",
    "    net.load_state_dict(torch.load(params.load_network_path))\n",
    "\n",
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\") # Verifica se há mais de uma GPU disponível\n",
    "net = torch.nn.DataParallel(net).to(device) # Paraleliza para usar mais de uma GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.shape: torch.Size([2, 1, 240, 424])\n"
     ]
    }
   ],
   "source": [
    "# Inicializa um tensor de teste\n",
    "test = net(torch.rand([2, 3, params.input_size[1], params.input_size[0]]).to(device), torch.rand([2, 1, params.input_size[1], params.input_size[0]]).to(device)) \n",
    "print('test.shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset\n"
     ]
    }
   ],
   "source": [
    "# Transformações para o dataset\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToPILImage(), # Converte o tensor para uma imagem PIL\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1), # Aplica valores aleatórios de brilho, contraste, saturação e matiz\n",
    "            transforms.ToTensor(), # Converte a imagem PIL para um tensor\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normaliza o tensor (média e desvio padrão)\n",
    "            ])\n",
    "\n",
    "dataset = TraversabilityDataset(params, transform) # Instancia um objeto da classe TraversabilityDataset\n",
    "\n",
    "# Divide o dataset em treino e validação \n",
    "train_size, val_size = int(0.8*len(dataset)), np.ceil(0.2*len(dataset)).astype('int')\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size]) # Separa os dados de acordo com os tamanhos estabelecidos e embaralha\n",
    "\n",
    "train_loader    = DataLoader(train_dataset, batch_size=params.batch_size, shuffle=True, num_workers=2)\n",
    "test_loader     = DataLoader(val_dataset, batch_size=params.batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# Informações sobre o dataset\n",
    "print('Total loaded %d images' % len(dataset))\n",
    "print('Loaded %d train images' % train_size)\n",
    "print('Loaded %d valid images' % val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo da primeira imagem do dataset\n",
    "data = train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.L1Loss(reduction='none') # Perda L1 (erro absoluto médio)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=params.learning_rate, weight_decay=params.weight_decay) # Verificar o melhor otimizador para o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_val_loss = np.inf # Melhor perda de validação\n",
    "train_loss_list = [] # Lista para armazenar as perdas de treino\n",
    "val_loss_list = [] # Lista para armazenar as perdas de validação\n",
    "\n",
    "accuracy_list = [] # Lista para armazenar as acurácias\n",
    "predc_list = [] # Lista para armazenar as predições\n",
    "\n",
    "# Treinamento\n",
    "for epoch in range(params.epochs):\n",
    "    net.train() # Modo de treino\n",
    "    train_loss = 0.0 # Setando a perda para 0 a cada época\n",
    "\n",
    "    # 'for' passando por cada imagem e cada dado do dataset\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = (item.to(device).type(torch.float32) for item in data) # Passa os dados para a GPU\n",
    "        color_img, depth_img, path_img, mu_img, nu_img, weight = data # Separa os dados em imagens e pesos\n",
    "\n",
    "        # Forward pass\n",
    "        pred = net(color_img, depth_img)\n",
    "        label = mu_img\n",
    "\n",
    "        loss = weight*criterion(pred*path_img, label) # Calcula a perda\n",
    "        loss = torch.mean(loss)\n",
    "        optimizer.zero_grad() # Zera os gradientes\n",
    "        loss.backward() # Backpropagation\n",
    "        optimizer.step() # Atualiza os pesos com o otimizador\n",
    "\n",
    "        train_loss += loss.item() # Somando a perda de cada batch\n",
    "\n",
    "    train_loss /= len(train_loader) # Calcula a perda média\n",
    "    train_loss_list.append(train_loss) # Adiciona a perda média na lista de perdas de treino\n",
    "        \n",
    "    # Apresenta a perda de treino a cada 10 épocas\n",
    "    if (epoch) % 10 == 0:\n",
    "        outstring = 'Epoch [%d/%d], Loss: ' % (epoch+1, params.epochs)\n",
    "        print(outstring, train_loss)\n",
    "        print('Learning Rate for this epoch: {}'.format(optimizer.param_groups[0]['lr']))\n",
    "    \n",
    "    # Testando o modelo \n",
    "    with torch.no_grad():\n",
    "        net.eval() # Modo de validação\n",
    "\n",
    "        val_loss = 0.0 # Setando a perda para 0 a cada época\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data = (item.to(device).type(torch.float32) for item in data)\n",
    "            color_img, depth_img, path_img, mu_img, nu_img, weight = data\n",
    "\n",
    "            pred = net(color_img, depth_img)\n",
    "            label = mu_img\n",
    "\n",
    "            loss = weight*criterion(pred*path_img, label)\n",
    "            loss = torch.mean(loss)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calcula a acurácia\n",
    "            _, preds = torch.max(pred, 1)\n",
    "            correct += torch.sum(preds == label.data)\n",
    "            total += label.size(0)\n",
    "\n",
    "        val_loss /= len(test_loader)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        accuracy_list.append(accuracy)\n",
    "        print(\"Precisão do modelo: \", accuracy)\n",
    "\n",
    "    # Apresenta a perda de validação\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        plt.figure(figsize = (14,14))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(color_img[0].permute(1, 2, 0).cpu().numpy())\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(255*pred[0,0,:,:].detach().cpu().numpy(), vmin=0, vmax=255)\n",
    "        plt.show(block=False)\n",
    "    \n",
    "    # Salva o modelo com a melhor perda de validação\n",
    "    if best_val_loss > val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print('Updating best validation loss: %.5f' % best_val_loss)\n",
    "        torch.save(net.module.state_dict(),'checkpoints/best_predictor_depth.pth')\n",
    "        \n",
    "    torch.save(net.module.state_dict(),'checkpoints/predictor_depth.pth')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
